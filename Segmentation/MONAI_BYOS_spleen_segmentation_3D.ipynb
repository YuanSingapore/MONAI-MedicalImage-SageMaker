{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "# Spleen 3D segmentation with MONAI\n",
    "\n",
    "This tutorial shows how to run SageMaker managed training using MONAI for 3D Segmentation.\n",
    "This tutorial shows how to run SageMaker managed inference after model training. \n",
    "\n",
    "\n",
    "\n",
    "This notebook and train.py script in source folder were derived from [spleen_segmentation_3d notebook](https://github.com/Project-MONAI/tutorials/blob/master/3d_segmentation/spleen_segmentation_3d.ipynb)\n",
    "\n",
    "Key features demonstrated here:\n",
    "1. SageMaker managed training with S3 integration\n",
    "2. SageMaker hosted inference \n",
    "\n",
    "The Spleen dataset can be downloaded from https://registry.opendata.aws/msd/.\n",
    "\n",
    "![spleen](http://medicaldecathlon.com/img/spleen0.png)\n",
    "\n",
    "Target: Spleen  \n",
    "Modality: CT  \n",
    "Size: 61 3D volumes (41 Training + 20 Testing)  \n",
    "Source: Memorial Sloan Kettering Cancer Center  \n",
    "Challenge: Large ranging foreground size\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install and import monai libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install  \"monai[all]==0.8.0\"\n",
    "!python -c \"import monai\" || pip install -q \"monai-weekly[gdown, nibabel, tqdm, ignite]\"\n",
    "!python -c \"import matplotlib\" || pip install -q matplotlib\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from monai.utils import first, set_determinism\n",
    "from monai.transforms import (\n",
    "    AsDiscrete,\n",
    "    AsDiscreted,\n",
    "    EnsureChannelFirstd,\n",
    "    Compose,\n",
    "    CropForegroundd,\n",
    "    LoadImaged,\n",
    "    Orientationd,\n",
    "    RandCropByPosNegLabeld,\n",
    "    ScaleIntensityRanged,\n",
    "    Spacingd,\n",
    "    EnsureTyped,\n",
    "    EnsureType,\n",
    "    Invertd,\n",
    ")\n",
    "from monai.handlers.utils import from_engine\n",
    "from monai.networks.nets import UNet\n",
    "from monai.networks.layers import Norm\n",
    "from monai.metrics import DiceMetric\n",
    "from monai.losses import DiceLoss\n",
    "from monai.inferers import sliding_window_inference\n",
    "from monai.data import CacheDataset, DataLoader, Dataset, decollate_batch\n",
    "from monai.config import print_config\n",
    "from monai.apps import download_and_extract\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import tempfile\n",
    "import shutil\n",
    "import os\n",
    "import glob\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import sagemaker libraries and get environment variables\n",
    "import sagemaker \n",
    "from sagemaker import get_execution_role\n",
    "role = get_execution_role()\n",
    "sess = sagemaker.Session()\n",
    "region = sess.boto_session.region_name\n",
    "bucket = sess.default_bucket()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the dataset: Spleen dataset\n",
    "+ Download the Spleen dataset if it is not available locally\n",
    "+ Transform the images using Compose from MONAI\n",
    "+ Visualize the image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the images\n",
    "resource = \"https://msd-for-monai.s3-us-west-2.amazonaws.com/Task09_Spleen.tar\"\n",
    "md5 = \"410d4a301da4e5b2f6f86ec3ddba524e\"\n",
    "compressed_file = \"./Task09_Spleen.tar\"\n",
    "\n",
    "MONAILabelServerIP = \"../Spleen3D\" ## you can change it to IP address of the MONAI Label Server if deployed\n",
    "data_dir = MONAILabelServerIP \n",
    "\n",
    "if not os.path.exists(data_dir):\n",
    "    download_and_extract(resource, compressed_file, data_dir+'/datasets', md5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## transform the images through Compose\n",
    "val_transforms = Compose(\n",
    "    [\n",
    "        LoadImaged(keys=[\"image\", \"label\"]),  ## keys include image and label with image first\n",
    "        EnsureChannelFirstd(keys=[\"image\", \"label\"]),\n",
    "        Spacingd(keys=[\"image\", \"label\"], pixdim=(\n",
    "            1.5, 1.5, 2.0), mode=(\"bilinear\", \"nearest\")),\n",
    "        Orientationd(keys=[\"image\", \"label\"], axcodes=\"RAS\"),\n",
    "        ScaleIntensityRanged(\n",
    "            keys=[\"image\"], a_min=-57, a_max=164,\n",
    "            b_min=0.0, b_max=1.0, clip=True,\n",
    "        ),\n",
    "        CropForegroundd(keys=[\"image\", \"label\"], source_key=\"image\"),\n",
    "        EnsureTyped(keys=[\"image\", \"label\"]),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## divide the images into training and testing dataset\n",
    "\n",
    "from monai.apps import download_and_extract\n",
    "import os\n",
    "import glob\n",
    "\n",
    "train_images = sorted(\n",
    "    glob.glob(os.path.join(data_dir, \"datasets/Task09_Spleen/imagesTr\", \"*.nii.gz\")))\n",
    "train_labels = sorted(\n",
    "    glob.glob(os.path.join(data_dir, \"datasets/Task09_Spleen/labelsTr\", \"*.nii.gz\")))\n",
    "data_dicts = [\n",
    "    {\"image\": image_name, \"label\": label_name}\n",
    "    for image_name, label_name in zip(train_images, train_labels)\n",
    "]\n",
    "train_files, val_files = data_dicts[:-1], data_dicts[-1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization\n",
    "\n",
    "check_ds = Dataset(data=val_files, transform=val_transforms)\n",
    "check_loader = DataLoader(check_ds, batch_size=1)\n",
    "check_data = first(check_loader)\n",
    "image, label = (check_data[\"image\"][0][0], check_data[\"label\"][0][0])\n",
    "print(f\"image shape: {image.shape}, label shape: {label.shape}\")\n",
    "# plot only the slice [:, :, 80]\n",
    "plt.figure(\"check\", (12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title(\"image\")\n",
    "plt.imshow(image[:, :, 80], cmap=\"gray\")\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title(\"label\")\n",
    "plt.imshow(label[:, :, 80])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training \n",
    "\n",
    "+ Divide the dataset into training and testing\n",
    "+ Upload the dataset into S3 \n",
    "+ SageMaker training job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## copy dataset for training \n",
    "!mkdir -p ../Spleen3D/train/imagesTr\n",
    "!mkdir -p ../Spleen3D/train/labelsTr\n",
    "\n",
    "## folder for testing dataset\n",
    "!mkdir -p ../Spleen3D/test/imagesTr\n",
    "!mkdir -p ../Spleen3D/test/labelsTr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## copy dataset for training \n",
    "for file in train_files:\n",
    "    image = file['image']\n",
    "    image_dest = \"../Spleen3D/train/imagesTr\"\n",
    "    label = file['label']\n",
    "    label_dest = \"../Spleen3D/train/labelsTr\"\n",
    "    shutil.copy(image,image_dest)\n",
    "    shutil.copy(label,label_dest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## copy dataset for testing  \n",
    "for file in val_files:\n",
    "    image = file['image']\n",
    "    image_dest = \"../Spleen3D/test/imagesTr\"\n",
    "    label = file['label']\n",
    "    label_dest = \"../Spleen3D/test/labelsTr\"\n",
    "    shutil.copy(image,image_dest)\n",
    "    shutil.copy(label,label_dest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## upload the dataset to S3\n",
    "prefix=\"MONAI-Segmentation\"\n",
    "bucket = sess.default_bucket()\n",
    "## upload training dataset\n",
    "S3_inputs = sess.upload_data(\n",
    "    path=\"../Spleen3D/train\",\n",
    "    key_prefix=prefix+\"/train\",\n",
    "    bucket=bucket \n",
    ")\n",
    "\n",
    "## upload testing dataset\n",
    "S3_test = sess.upload_data(\n",
    "    path=\"../Spleen3D/test\",\n",
    "    key_prefix=prefix+\"/test\",\n",
    "    bucket=bucket \n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SageMaker training job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "import sagemaker\n",
    "from sagemaker.inputs import FileSystemInput\n",
    "from sagemaker.pytorch import PyTorch\n",
    "\n",
    "metrics=[\n",
    "   {'Name': 'train:average epoch loss', 'Regex': 'average loss: ([0-9\\\\.]*)'},\n",
    "   {'Name': 'train:current mean dice', 'Regex': 'current mean dice: ([0-9\\\\.]*)'},\n",
    "   {'Name': 'train:best mean dice', 'Regex': 'best mean dice: ([0-9\\\\.]*)'}\n",
    "]\n",
    "\n",
    "estimator = PyTorch(source_dir='code',\n",
    "                    entry_point='train.py',\n",
    "                    role=role,\n",
    "                    framework_version='1.6.0',\n",
    "                    py_version='py3',\n",
    "                    instance_count=1,\n",
    "                    instance_type='ml.p2.xlarge',\n",
    "                    hyperparameters={\n",
    "                       \"seed\": 123,\n",
    "                       \"lr\": 0.001,\n",
    "                       \"epochs\": 10\n",
    "                    },\n",
    "                    metric_definitions=metrics,\n",
    "#                     ### spot instance training ###\n",
    "#                    use_spot_instances=True,\n",
    "#                     max_run=2400,\n",
    "#                     max_wait=2400\n",
    "                )\n",
    "\n",
    "\n",
    "estimator.fit(S3_inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Inference \n",
    "\n",
    "+ deploy the model with customized inference script\n",
    "+ inference with testing image in S3\n",
    "+ visualization the results\n",
    "+ deployment with trained estimator or the model artifact in S3.\n",
    "\n",
    "\n",
    "### Type of inference\n",
    "SageMaker provides the flexibility of deploying endpoints with the following 3 options: \n",
    "+ realtime inference\n",
    "+ asychronous inference\n",
    "+ batch transform\n",
    "\n",
    "Customers can select the corresponding option based on the budget and requirements. \n",
    "\n",
    "I am going to demonstrate the realtime and asynchronous deployment options in the following scripts \n",
    "Due to size of the model output, we chose to use asychronous inference to save output in S3 bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## you can get the model artifact here\n",
    "model_data=estimator.__dict__['output_path']+estimator.__dict__['_current_job_name']+'/output/model.tar.gz'\n",
    "\n",
    "## a neater version to fetch model artifact\n",
    "model_data=estimator.latest_training_job.describe()[\"ModelArtifacts\"][\"S3ModelArtifacts\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.pytorch.model import PyTorchModel\n",
    "\n",
    "model = PyTorchModel(\n",
    "    entry_point=\"inference.py\", ## inference code with customization\n",
    "    role=role,\n",
    "    model_data=model_data,\n",
    "    framework_version=\"1.5.0\",\n",
    "    py_version=\"py3\",\n",
    ")\n",
    "\n",
    "predictor = model.deploy(\n",
    "    initial_instance_count = 1, \n",
    "    instance_type = 'ml.m5.2xlarge',\n",
    "    serializer=sagemaker.serializers.JSONSerializer(),\n",
    "    deserializer=sagemaker.deserializers.JSONDeserializer()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "payload={\"bucket\": 'sagemaker-us-east-1-741261399688',\n",
    "    \"key\":\"MONAI-Segmentation/test/imagesTr\",\n",
    "    \"file\":'spleen_9.nii.gz',\n",
    "    \"nslice\":80}\n",
    "\n",
    "\n",
    "response=predictor.predict(payload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "payload={\"bucket\": 'sagemaker-us-east-1-741261399688',\n",
    "    \"key\":\"MONAI-Segmentation/test/imagesTr\",\n",
    "    \"file\":'spleen_9.nii.gz',\n",
    "    \"nslice\":100}\n",
    "\n",
    "\n",
    "response=predictor.predict(payload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "payload={\"bucket\": 'sagemaker-us-east-1-741261399688',\n",
    "    \"key\":\"MONAI-Segmentation/test/imagesTr\",\n",
    "    \"file\":'spleen_9.nii.gz',\n",
    "    \"nslice\":200}\n",
    "\n",
    "\n",
    "response=predictor.predict(payload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference \n",
    "\n",
    "+ deploy the model with customized inference script\n",
    "+ inference with testing image in S3\n",
    "+ visualization the results\n",
    "+ deployment with trained estimator or the model artifact in S3.\n",
    "\n",
    "\n",
    "### Type of inference\n",
    "SageMaker provides the flexibility of deploying endpoints with the following 3 options: \n",
    "+ realtime inference\n",
    "+ asychronous inference\n",
    "+ batch transform\n",
    "\n",
    "Customers can select the corresponding option based on the budget and requirements. \n",
    "\n",
    "I am going to demonstrate the realtime and asynchronous deployment options in the following scripts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## realtime endpoint\n",
    "\n",
    "predictor = estimator.deploy(initial_instance_count=1,entry_point='inference.py', instance_type='ml.m5.2xlarge',serializer=sagemaker.serializers.JSONSerializer(),deserializer=sagemaker.deserializers.JSONDeserializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "payload={\"bucket\": 'sagemaker-us-east-1-741261399688',\n",
    "    \"key\":\"MONAI-Segmentation/test/imagesTr\",\n",
    "    \"file\":'spleen_9.nii.gz',\n",
    "    \"nslice\":80}\n",
    "response=predictor.predict(payload)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Asynchronous inference endpoint\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.async_inference import AsyncInferenceConfig\n",
    "\n",
    "s3_bucket=bucket\n",
    "\n",
    "bucket_prefix = 'Inference_output' ## output for the inference\n",
    "output_path=f\"s3://{s3_bucket}/{bucket_prefix}/segmentation/output\"\n",
    "\n",
    "async_config = AsyncInferenceConfig(\n",
    "    output_path=output_path,\n",
    "    max_concurrent_invocations_per_instance=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor_async = estimator.deploy(initial_instance_count=1,\n",
    "                             entry_point='inference_async.py', \n",
    "                             instance_type='ml.m5.2xlarge',\n",
    "                             serializer=sagemaker.serializers.JSONSerializer(),\n",
    "                             deserializer=sagemaker.deserializers.JSONDeserializer(),\n",
    "                             async_inference_config=async_config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "payload={\"bucket\": 'sagemaker-us-east-1-741261399688',\n",
    "    \"key\":\"MONAI-Segmentation/test/imagesTr\",\n",
    "    \"file\":'spleen_9.nii.gz',\n",
    "    \"nslice\":200}\n",
    "\n",
    "\n",
    "response=predictor_async.predict(payload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "payload={\"bucket\": 'sagemaker-us-east-1-741261399688',\n",
    "    \"key\":\"MONAI-Segmentation/test/imagesTr\",\n",
    "    \"file\":'spleen_9.nii.gz',\n",
    "    \"nslice\":70}\n",
    "\n",
    "\n",
    "response=predictor_async.predict(payload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('input.json', 'w') as f:\n",
    "    json.dump(payload, f)\n",
    "    \n",
    "## upload testing dataset\n",
    "input_payload = sess.upload_data(\n",
    "    path=\"input.json\",\n",
    "    key_prefix=prefix+\"/test_json\",\n",
    "    bucket=bucket \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "input_payload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "response=predictor_async.predict(input_path=input_payload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tears down the SageMaker endpoint and endpoint configuration if no longer needed\n",
    "predictor_async.delete_endpoint()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visulaize the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.Tensor(response[\"pred\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, val_data in enumerate(val_loader):\n",
    "        \n",
    "        # plot the slice [:, :, 80]\n",
    "        plt.figure(\"check\", (18, 6))\n",
    "        plt.subplot(1, 3, 1)\n",
    "        plt.title(f\"image {i}\")\n",
    "        plt.imshow(val_data[\"image\"][0, 0, :, :, 80], cmap=\"gray\")\n",
    "        plt.subplot(1, 3, 2)\n",
    "        plt.title(f\"label {i}\")\n",
    "        plt.imshow(val_data[\"label\"][0, 0, :, :, 80])\n",
    "        plt.subplot(1,3, 3)\n",
    "        plt.title(f\"output {i}\")\n",
    "        plt.imshow(torch.Tensor(response[\"pred\"]))\n",
    "\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean up the resources\n",
    "\n",
    "+ delete all the endpoints to save cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "client = boto3.client('sagemaker')\n",
    "endpoints=client.list_endpoints()['Endpoints']\n",
    "endpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for endpoint in endpoints:\n",
    "    response = client.delete_endpoint(\n",
    "        EndpointName=endpoint['EndpointName']\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "conda_pytorch_latest_p36",
   "language": "python",
   "name": "conda_pytorch_latest_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
