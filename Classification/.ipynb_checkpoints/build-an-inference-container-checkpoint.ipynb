{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1dd79cd",
   "metadata": {},
   "source": [
    "## Build an Consum Inference Container"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d40f1f2",
   "metadata": {},
   "source": [
    "his notebook demonstrates how to build and use a custom Docker container for serving with Amazon SageMaker that leverages on <strong>sagemaker-inference-toolkit</strong> libraries for serving models through Amazon SageMaker's endpoints.\n",
    "\n",
    "\n",
    "Useful links:\n",
    "- https://github.com/awslabs/multi-model-server/\n",
    "- https://github.com/aws/sagemaker-inference-toolkit\n",
    "\n",
    "- https://github.com/aws-samples/amazon-sagemaker-mask-r-cnn-pytorch/blob/master/MaskRCNN_bring_your_own.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc2bb051",
   "metadata": {},
   "source": [
    "We start by defining some variables like the current execution role, the ECR repository that we are going to use for pushing the custom Docker container and a default Amazon S3 bucket to be used by Amazon SageMaker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9d580125",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "707754867495\n",
      "us-east-1\n",
      "arn:aws:iam::707754867495:role/SageMakerAPIExecutionRoleName-707754867495\n",
      "sagemaker-us-east-1-707754867495\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "ecr_namespace = 'sagemaker-serving-containers/'\n",
    "prefix = 'medical-image-server-container'\n",
    "\n",
    "ecr_repository_name = ecr_namespace + prefix\n",
    "role = get_execution_role()\n",
    "account_id = role.split(':')[4]\n",
    "region = boto3.Session().region_name\n",
    "sagemaker_session = sagemaker.session.Session()\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "\n",
    "print(account_id)\n",
    "print(region)\n",
    "print(role)\n",
    "print(bucket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e95c7016",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[37m# Build an image that can do training and inference in SageMaker\u001b[39;49;00m\r\n",
      "\u001b[37m# This is a Python 3 image that uses the nginx, gunicorn, flask stack\u001b[39;49;00m\r\n",
      "\u001b[37m# for serving inferences in a stable way.\u001b[39;49;00m\r\n",
      "\r\n",
      "\u001b[34mFROM\u001b[39;49;00m \u001b[33mubuntu:16.04\u001b[39;49;00m\r\n",
      "\r\n",
      "\u001b[34mRUN\u001b[39;49;00m apt-get -y update && apt-get install -y --no-install-recommends \u001b[33m\\\u001b[39;49;00m\r\n",
      "         wget \u001b[33m\\\u001b[39;49;00m\r\n",
      "         gcc\u001b[33m\\\u001b[39;49;00m\r\n",
      "         g++\u001b[33m\\\u001b[39;49;00m\r\n",
      "         python3 \u001b[33m\\\u001b[39;49;00m\r\n",
      "         python3-dev\u001b[33m\\\u001b[39;49;00m\r\n",
      "         nginx \u001b[33m\\\u001b[39;49;00m\r\n",
      "         ca-certificates \u001b[33m\\\u001b[39;49;00m\r\n",
      "    && rm -rf /var/lib/apt/lists/*\r\n",
      "\r\n",
      "\u001b[37m# Here we get all python packages.\u001b[39;49;00m\r\n",
      "\u001b[37m# There's substantial overlap between scipy and numpy that we eliminate by\u001b[39;49;00m\r\n",
      "\u001b[37m# linking them together. Likewise, pip leaves the install caches populated which uses\u001b[39;49;00m\r\n",
      "\u001b[37m# a significant amount of space. These optimizations save a fair amount of space in the\u001b[39;49;00m\r\n",
      "\u001b[37m# image, which reduces start up time.\u001b[39;49;00m\r\n",
      "\u001b[34mRUN\u001b[39;49;00m wget https://bootstrap.pypa.io/get-pip.py && python3 get-pip.py && \u001b[33m\\\u001b[39;49;00m\r\n",
      "    pip install cython \u001b[31mnumpy\u001b[39;49;00m==\u001b[34m1\u001b[39;49;00m.16.2 \u001b[31mscipy\u001b[39;49;00m==\u001b[34m1\u001b[39;49;00m.2.1 pandas flask gevent gunicorn && \u001b[33m\\\u001b[39;49;00m\r\n",
      "        (\u001b[36mcd\u001b[39;49;00m /usr/local/lib/python3.5/dist-packages/scipy/.libs; rm *; ln ../../numpy/.libs/* .) && \u001b[33m\\\u001b[39;49;00m\r\n",
      "        rm -rf /root/.cache\r\n",
      "        \r\n",
      "        \r\n",
      "\u001b[34mRUN\u001b[39;49;00m ln -s /usr/bin/python3 /usr/bin/python & \u001b[33m\\\u001b[39;49;00m\r\n",
      "    ln -s /usr/bin/pip3 /usr/bin/pip\r\n",
      "\u001b[34mRUN\u001b[39;49;00m pip install scikit-learn==\u001b[34m0\u001b[39;49;00m.22 \u001b[31mtorch\u001b[39;49;00m==\u001b[34m1\u001b[39;49;00m.4 \u001b[31mtorchvision\u001b[39;49;00m==\u001b[34m0\u001b[39;49;00m.5.0  fastai thinc  Pillow pycocotools\r\n",
      "\u001b[37m# Set some environment variables. PYTHONUNBUFFERED keeps Python from buffering our standard\u001b[39;49;00m\r\n",
      "\u001b[37m# output stream, which means that logs can be delivered to the user quickly. PYTHONDONTWRITEBYTECODE\u001b[39;49;00m\r\n",
      "\u001b[37m# keeps Python from writing the .pyc files which are unnecessary in this case. We also update\u001b[39;49;00m\r\n",
      "\u001b[37m# PATH so that the train and serve programs are found when the container is invoked.\u001b[39;49;00m\r\n",
      "\r\n",
      "\u001b[34mENV\u001b[39;49;00m \u001b[31mPYTHONUNBUFFERED\u001b[39;49;00m=TRUE\r\n",
      "\u001b[34mENV\u001b[39;49;00m \u001b[31mPYTHONDONTWRITEBYTECODE\u001b[39;49;00m=TRUE\r\n",
      "\u001b[34mENV\u001b[39;49;00m \u001b[31mPATH\u001b[39;49;00m=\u001b[33m\"\u001b[39;49;00m\u001b[33m/opt/program:\u001b[39;49;00m\u001b[33m${\u001b[39;49;00m\u001b[31mPATH\u001b[39;49;00m\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\r\n",
      "\r\n",
      "\u001b[37m# Set up the program in the image\u001b[39;49;00m\r\n",
      "\u001b[34mCOPY\u001b[39;49;00m Image_Inference /opt/program\r\n",
      "\u001b[37m# install all the packages in requirements\u001b[39;49;00m\r\n",
      "\u001b[34mRUN\u001b[39;49;00m pip install -r /opt/program/requirements.txt\r\n",
      "\r\n",
      "\u001b[34mWORKDIR\u001b[39;49;00m\u001b[33m /opt/program\u001b[39;49;00m\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\u001b[37m#COPY code/serve.py /serve.py\u001b[39;49;00m\r\n",
      "\u001b[34mENTRYPOINT\u001b[39;49;00m [\u001b[33m\"python\"\u001b[39;49;00m, \u001b[33m\"serve.py\"\u001b[39;49;00m]\r\n"
     ]
    }
   ],
   "source": [
    "! pygmentize Dockerfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab4a5e36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[37m#!/usr/bin/env bash\u001b[39;49;00m\r\n",
      "\r\n",
      "\u001b[37m# This script shows how to build the Docker image and push it to ECR to be ready for use\u001b[39;49;00m\r\n",
      "\u001b[37m# by SageMaker.\u001b[39;49;00m\r\n",
      "\r\n",
      "\u001b[37m# The argument to this script is the image name. This will be used as the image on the local\u001b[39;49;00m\r\n",
      "\u001b[37m# machine and combined with the account and region to form the repository name for ECR.\u001b[39;49;00m\r\n",
      "\u001b[31mimage\u001b[39;49;00m=\u001b[31m$1\u001b[39;49;00m\r\n",
      "\u001b[36mecho\u001b[39;49;00m \u001b[33m${\u001b[39;49;00m\u001b[31mimage\u001b[39;49;00m\u001b[33m}\u001b[39;49;00m\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\u001b[34mif\u001b[39;49;00m [ \u001b[33m\"\u001b[39;49;00m\u001b[31m$image\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m == \u001b[33m\"\"\u001b[39;49;00m ]\r\n",
      "\u001b[34mthen\u001b[39;49;00m\r\n",
      "    \u001b[36mecho\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mUsage: \u001b[39;49;00m\u001b[31m$0\u001b[39;49;00m\u001b[33m <image-name>\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\r\n",
      "    \u001b[36mexit\u001b[39;49;00m \u001b[34m1\u001b[39;49;00m\r\n",
      "\u001b[34mfi\u001b[39;49;00m\r\n",
      "\r\n",
      "\u001b[37m# provide access to the local folder\u001b[39;49;00m\r\n",
      "chmod +x Image_Inference\r\n",
      "\r\n",
      "\u001b[37m# Get the account number associated with the current IAM credentials\u001b[39;49;00m\r\n",
      "\u001b[31maccount\u001b[39;49;00m=\u001b[34m$(\u001b[39;49;00maws sts get-caller-identity --query Account --output text\u001b[34m)\u001b[39;49;00m\r\n",
      "\r\n",
      "\u001b[34mif\u001b[39;49;00m [ \u001b[31m$?\u001b[39;49;00m -ne \u001b[34m0\u001b[39;49;00m ]\r\n",
      "\u001b[34mthen\u001b[39;49;00m\r\n",
      "    \u001b[36mexit\u001b[39;49;00m \u001b[34m255\u001b[39;49;00m\r\n",
      "\u001b[34mfi\u001b[39;49;00m\r\n",
      "\r\n",
      "\r\n",
      "\u001b[37m# Get the region defined in the current configuration (default to us-west-2 if none defined)\u001b[39;49;00m\r\n",
      "\u001b[31mregion\u001b[39;49;00m=\u001b[34m$(\u001b[39;49;00maws configure get region\u001b[34m)\u001b[39;49;00m\r\n",
      "\u001b[31mregion\u001b[39;49;00m=\u001b[33m${\u001b[39;49;00m\u001b[31mregion\u001b[39;49;00m\u001b[34m:-\u001b[39;49;00m\u001b[31mus\u001b[39;49;00m-east-1\u001b[33m}\u001b[39;49;00m\r\n",
      "\u001b[36mecho\u001b[39;49;00m \u001b[33m${\u001b[39;49;00m\u001b[31mregion\u001b[39;49;00m\u001b[33m}\u001b[39;49;00m\r\n",
      "\r\n",
      "\u001b[31mfullname\u001b[39;49;00m=\u001b[33m\"\u001b[39;49;00m\u001b[33m${\u001b[39;49;00m\u001b[31maccount\u001b[39;49;00m\u001b[33m}\u001b[39;49;00m\u001b[33m.dkr.ecr.\u001b[39;49;00m\u001b[33m${\u001b[39;49;00m\u001b[31mregion\u001b[39;49;00m\u001b[33m}\u001b[39;49;00m\u001b[33m.amazonaws.com/\u001b[39;49;00m\u001b[33m${\u001b[39;49;00m\u001b[31mimage\u001b[39;49;00m\u001b[33m}\u001b[39;49;00m\u001b[33m:latest\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\r\n",
      "\r\n",
      "\u001b[37m# If the repository doesn't exist in ECR, create it.\u001b[39;49;00m\r\n",
      "\r\n",
      "aws ecr describe-repositories --repository-names \u001b[33m\"\u001b[39;49;00m\u001b[33m${\u001b[39;49;00m\u001b[31mimage\u001b[39;49;00m\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m > /dev/null \u001b[34m2\u001b[39;49;00m>&\u001b[34m1\u001b[39;49;00m\r\n",
      "\r\n",
      "\u001b[34mif\u001b[39;49;00m [ \u001b[31m$?\u001b[39;49;00m -ne \u001b[34m0\u001b[39;49;00m ]\r\n",
      "\u001b[34mthen\u001b[39;49;00m\r\n",
      "    aws ecr create-repository --repository-name \u001b[33m\"\u001b[39;49;00m\u001b[33m${\u001b[39;49;00m\u001b[31mimage\u001b[39;49;00m\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m > /dev/null\r\n",
      "\u001b[34mfi\u001b[39;49;00m\r\n",
      "\r\n",
      "\u001b[37m# Get the login command from ECR and execute it directly\u001b[39;49;00m\r\n",
      "\u001b[34m$(\u001b[39;49;00maws ecr get-login --region \u001b[33m${\u001b[39;49;00m\u001b[31mregion\u001b[39;49;00m\u001b[33m}\u001b[39;49;00m --no-include-email\u001b[34m)\u001b[39;49;00m\r\n",
      "\r\n",
      "\u001b[37m# Build the docker image locally with the image name and then push it to ECR\u001b[39;49;00m\r\n",
      "\u001b[37m# with the full name.\u001b[39;49;00m\r\n",
      "\r\n",
      "docker build  -t \u001b[33m${\u001b[39;49;00m\u001b[31mimage\u001b[39;49;00m\u001b[33m}\u001b[39;49;00m .\r\n",
      "docker tag \u001b[33m${\u001b[39;49;00m\u001b[31mimage\u001b[39;49;00m\u001b[33m}\u001b[39;49;00m \u001b[33m${\u001b[39;49;00m\u001b[31mfullname\u001b[39;49;00m\u001b[33m}\u001b[39;49;00m\r\n",
      "\r\n",
      "docker push \u001b[33m${\u001b[39;49;00m\u001b[31mfullname\u001b[39;49;00m\u001b[33m}\u001b[39;49;00m\r\n"
     ]
    }
   ],
   "source": [
    "! pygmentize build_and_push.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b6919da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = 'medical-image-server-container'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9302371a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!build_and_push.sh $prefix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "33759b30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\r\n",
      "    \"imageIds\": [\r\n",
      "        {\r\n",
      "            \"imageDigest\": \"sha256:94a17bc8ed66f0440f043f1006411530f9c35744a66b91a4184b26d36e65c619\",\r\n",
      "            \"imageTag\": \"latest\"\r\n",
      "        }\r\n",
      "    ]\r\n",
      "}\r\n"
     ]
    }
   ],
   "source": [
    "!aws ecr list-images \\\n",
    "    --repository-name $prefix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd67c05b",
   "metadata": {},
   "source": [
    "## Use the image for prediction "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a7e303",
   "metadata": {},
   "source": [
    "find the model artifact in S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3ce76459",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_model_path = 's3://sagemaker-us-east-1-707754867495/pytorch-training-2022-01-27-07-48-30-122/output/model.tar.gz'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b33f1205",
   "metadata": {},
   "source": [
    "find the image uri from ECR "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b90eaf39",
   "metadata": {},
   "outputs": [],
   "source": [
    "container_image_uri = '{0}.dkr.ecr.{1}.amazonaws.com/{2}:latest'.format(account_id, region, prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7e2605c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'arn:aws:iam::707754867495:role/SageMakerAPIExecutionRoleName-707754867495'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0f4eaf1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import gmtime, strftime\n",
    "from sagemaker.model import Model\n",
    "\n",
    "model_name = 'medical-image-model-server-model-' + strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "\n",
    "model = Model(model_data = s3_model_path,\n",
    "              image_uri = container_image_uri,\n",
    "              env = {\n",
    "                  'SAGEMAKER_PROGRAM': 'predictor'\n",
    "              },\n",
    "              role=role,\n",
    "              name = model_name,\n",
    "              predictor_cls = sagemaker.predictor.Predictor,\n",
    "              #sagemaker_session=sagemaker_session #comment this line for local mode.\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d58651dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker_client = boto3.client('sagemaker', region_name='us-east-1')\n",
    "                                \n",
    "model_name = 'medical-image-model-server-model-' + strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "\n",
    "create_model_response = sagemaker_client.create_model(\n",
    "    ModelName = model_name,\n",
    "    ExecutionRoleArn = role,\n",
    "    PrimaryContainer = {\n",
    "        'Image': container_image_uri,\n",
    "        'ModelDataUrl': s3_model_path,\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f41352d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ModelArn': 'arn:aws:sagemaker:us-east-1:707754867495:model/medical-image-model-server-model-2022-02-23-06-29-26',\n",
       " 'ResponseMetadata': {'RequestId': '6093f743-7d7e-4be5-b916-59e2a4f430e8',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': '6093f743-7d7e-4be5-b916-59e2a4f430e8',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '114',\n",
       "   'date': 'Wed, 23 Feb 2022 06:29:25 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_model_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "179b80e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_prefix = 'Inference_output'\n",
    "bucket = sagemaker_session.default_bucket()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "745435e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## create a endpoint configure "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "786689f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created EndpointConfig: arn:aws:sagemaker:us-east-1:707754867495:endpoint-config/medicalimageendpointconfig-2022-02-23-08-19-43\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "from time import gmtime, strftime\n",
    "\n",
    "# Create an endpoint config name. Here we create one based on the date  \n",
    "# so it we can search endpoints based on creation time.\n",
    "endpoint_config_name = f\"MedicalImageEndpointConfig-{strftime('%Y-%m-%d-%H-%M-%S', gmtime())}\"\n",
    "\n",
    "# The name of the model that you want to host. This is the name that you specified when creating the model.\n",
    "model_name='pytorch-inference-2022-01-27-08-48-43-106'\n",
    "\n",
    "create_endpoint_config_response = sagemaker_client.create_endpoint_config(\n",
    "    EndpointConfigName=endpoint_config_name, # You will specify this name in a CreateEndpoint request.\n",
    "    # List of ProductionVariant objects, one for each model that you want to host at this endpoint.\n",
    "    ProductionVariants=[\n",
    "        {\n",
    "            \"VariantName\": \"variant1\", # The name of the production variant.\n",
    "            \"ModelName\": model_name, \n",
    "            \"InstanceType\": \"ml.m5.xlarge\", # Specify the compute instance type.\n",
    "            \"InitialInstanceCount\": 1 # Number of instances to launch initially.\n",
    "        }\n",
    "    ],\n",
    "    AsyncInferenceConfig={\n",
    "        \"OutputConfig\": {\n",
    "            # Location to upload response outputs when no location is provided in the request.\n",
    "            \"S3OutputPath\": f\"s3://{bucket}/{bucket_prefix}/output\",\n",
    "            # (Optional) specify Amazon SNS topics\n",
    "            \n",
    "        },\n",
    "        \"ClientConfig\": {\n",
    "            # (Optional) Specify the max number of inflight invocations per instance\n",
    "            # If no value is provided, Amazon SageMaker will choose an optimal value for you\n",
    "            \"MaxConcurrentInvocationsPerInstance\": 4\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "print(f\"Created EndpointConfig: {create_endpoint_config_response['EndpointConfigArn']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "88d64e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint_name = 'AsynchronousMedicalInference3' \n",
    "\n",
    "# The name of the endpoint configuration associated with this endpoint.\n",
    "\n",
    "create_endpoint_response = sagemaker_client.create_endpoint(\n",
    "                                            EndpointName=endpoint_name, \n",
    "                                            EndpointConfigName=endpoint_config_name,\n",
    "                                           ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5ba4df3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AsynchronousMedicalInference3'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "endpoint_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7ec294d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## invoke the endpoint\n",
    "sagemaker_runtime = boto3.client(\"sagemaker-runtime\", region_name='us-east-1')\n",
    "input_location = 's3://sagemaker-us-east-1-707754867495/inference_input/test-2.json'\n",
    "response = sagemaker_runtime.invoke_endpoint_async(\n",
    "    EndpointName=endpoint_name,\n",
    "    InputLocation=input_location\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "7a9427f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': '0b1e8cca-c5a0-4920-a093-2cefa7a50929',\n",
       "  'HTTPStatusCode': 202,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': '0b1e8cca-c5a0-4920-a093-2cefa7a50929',\n",
       "   'x-amzn-sagemaker-outputlocation': 's3://sagemaker-us-east-1-707754867495/Inference_output/output/f99f3083-c41a-4deb-8dce-d8c9b759138a.out',\n",
       "   'date': 'Wed, 23 Feb 2022 09:34:25 GMT',\n",
       "   'content-type': 'application/json',\n",
       "   'content-length': '54'},\n",
       "  'RetryAttempts': 0},\n",
       " 'OutputLocation': 's3://sagemaker-us-east-1-707754867495/Inference_output/output/f99f3083-c41a-4deb-8dce-d8c9b759138a.out',\n",
       " 'InferenceId': 'd2c2d7d9-1179-4d9c-b90f-26c6c8b063b4'}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c96e3ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
