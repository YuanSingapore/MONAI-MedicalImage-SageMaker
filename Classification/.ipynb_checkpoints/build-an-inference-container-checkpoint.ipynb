{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "531dd5ef",
   "metadata": {},
   "source": [
    "## Build an Consum Inference Container"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f75de080",
   "metadata": {},
   "source": [
    "his notebook demonstrates how to build and use a custom Docker container for serving with Amazon SageMaker that leverages on <strong>sagemaker-inference-toolkit</strong> libraries for serving models through Amazon SageMaker's endpoints.\n",
    "\n",
    "\n",
    "Useful links:\n",
    "- https://github.com/awslabs/multi-model-server/\n",
    "- https://github.com/aws/sagemaker-inference-toolkit\n",
    "\n",
    "- https://github.com/aws-samples/amazon-sagemaker-mask-r-cnn-pytorch/blob/master/MaskRCNN_bring_your_own.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b4868a",
   "metadata": {},
   "source": [
    "We start by defining some variables like the current execution role, the ECR repository that we are going to use for pushing the custom Docker container and a default Amazon S3 bucket to be used by Amazon SageMaker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "77c0524d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "741261399688\n",
      "us-east-1\n",
      "arn:aws:iam::741261399688:role/service-role/AmazonSageMaker-ExecutionRole-20191114T174410\n",
      "sagemaker-us-east-1-741261399688\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "ecr_namespace = 'monai-classification'\n",
    "#prefix = 'medical-image-server-container'\n",
    "\n",
    "ecr_repository_name = ecr_namespace\n",
    "role = get_execution_role()\n",
    "account_id = role.split(':')[4]\n",
    "region = boto3.Session().region_name\n",
    "sess = sagemaker.session.Session()\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "bucket_prefix = 'Inference_output' ## output for the results\n",
    "\n",
    "\n",
    "print(account_id)\n",
    "print(region)\n",
    "print(role)\n",
    "print(bucket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80ea77ac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mFROM\u001b[39;49;00m \u001b[33mpython:3.7\u001b[39;49;00m\r\n",
      "\u001b[34mARG\u001b[39;49;00m \u001b[31mNB_USER\u001b[39;49;00m=\u001b[33m\"sagemaker-user\"\u001b[39;49;00m\r\n",
      "\u001b[34mARG\u001b[39;49;00m \u001b[31mNB_UID\u001b[39;49;00m=\u001b[33m\"1000\"\u001b[39;49;00m\r\n",
      "\u001b[34mARG\u001b[39;49;00m \u001b[31mNB_GID\u001b[39;49;00m=\u001b[33m\"100\"\u001b[39;49;00m\r\n",
      "\u001b[34mRUN\u001b[39;49;00m \u001b[33m\\\u001b[39;49;00m\r\n",
      "    apt-get update && \u001b[33m\\\u001b[39;49;00m\r\n",
      "    apt-get install -y sudo && \u001b[33m\\\u001b[39;49;00m\r\n",
      "    useradd -m -s /bin/bash -N -u \u001b[31m$NB_UID\u001b[39;49;00m \u001b[31m$NB_USER\u001b[39;49;00m && \u001b[33m\\\u001b[39;49;00m\r\n",
      "    chmod g+w /etc/passwd && \u001b[33m\\\u001b[39;49;00m\r\n",
      "    \u001b[36mecho\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33m${\u001b[39;49;00m\u001b[31mNB_USER\u001b[39;49;00m\u001b[33m}\u001b[39;49;00m\u001b[33m    ALL=(ALL)    NOPASSWD:    ALL\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m >> /etc/sudoers && \u001b[33m\\\u001b[39;49;00m\r\n",
      "    # Prevent apt-get cache from being persisted to this layer.\r\n",
      "    rm -rf /var/lib/apt/lists/*\r\n",
      "\u001b[34mRUN\u001b[39;49;00m pip install \u001b[33m\\\u001b[39;49;00m\r\n",
      "        \u001b[33m'boto3>=1,<2'\u001b[39;49;00m \u001b[33m\\\u001b[39;49;00m\r\n",
      "        \u001b[33m'sagemaker>=2,<3'\u001b[39;49;00m \u001b[33m\\\u001b[39;49;00m\r\n",
      "        \u001b[33m'sagemaker-experiments>=0.1,<0.2'\u001b[39;49;00m \u001b[33m\\\u001b[39;49;00m\r\n",
      "        \u001b[33m'sagemaker-studio-image-build>=0.4,<0.5'\u001b[39;49;00m \u001b[33m\\\u001b[39;49;00m\r\n",
      "        \u001b[33m'smdebug>=0.9,<0.10'\u001b[39;49;00m\r\n",
      "\u001b[34mRUN\u001b[39;49;00m pip install \u001b[33m'monai[all]==0.8.0'\u001b[39;49;00m\r\n",
      "\u001b[37m#RUN python -m pip install -U 'scikit-image>=3.0.7'\u001b[39;49;00m\r\n",
      "\u001b[34mENV\u001b[39;49;00m \u001b[31mPYTHONUNBUFFERED\u001b[39;49;00m=TRUE\r\n",
      "\u001b[34mENV\u001b[39;49;00m \u001b[31mPYTHONDONTWRITEBYTECODE\u001b[39;49;00m=TRUE\r\n",
      "\u001b[34mENV\u001b[39;49;00m \u001b[31mPATH\u001b[39;49;00m=\u001b[33m\"\u001b[39;49;00m\u001b[33m/opt/ml/code:\u001b[39;49;00m\u001b[33m${\u001b[39;49;00m\u001b[31mPATH\u001b[39;49;00m\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\r\n",
      "\r\n",
      "\u001b[37m# Set up the program in the image\u001b[39;49;00m\r\n",
      "\u001b[34mCOPY\u001b[39;49;00m /code_byoc /opt/ml/code\r\n",
      "\u001b[37m# install all the packages in requirements\u001b[39;49;00m\r\n",
      "\r\n",
      "\u001b[34mWORKDIR\u001b[39;49;00m\u001b[33m /opt/ml/code\u001b[39;49;00m\r\n",
      "\r\n",
      "\r\n",
      "\u001b[34mENTRYPOINT\u001b[39;49;00m [\u001b[33m\"python\"\u001b[39;49;00m, \u001b[33m\"serve.py\"\u001b[39;49;00m]\r\n"
     ]
    }
   ],
   "source": [
    "! pygmentize Dockerfile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a43092cd",
   "metadata": {},
   "source": [
    "## build and push the container image to ECR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "342a2730",
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = 'monai-classification'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6031f896",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!build_and_push.sh $prefix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d19f34fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\r\n",
      "    \"imageIds\": [\r\n",
      "        {\r\n",
      "            \"imageDigest\": \"sha256:1c0c40b0755054a9e13ddb10124fe28f308aacda85ec2d1d4d6253197b7d943f\",\r\n",
      "            \"imageTag\": \"latest\"\r\n",
      "        }\r\n",
      "    ]\r\n",
      "}\r\n"
     ]
    }
   ],
   "source": [
    "!aws ecr list-images \\\n",
    "    --repository-name $prefix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1103f8ae",
   "metadata": {},
   "source": [
    "## Use the image for prediction "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f68f5711",
   "metadata": {},
   "source": [
    "find the model artifact in S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c2ca5877",
   "metadata": {},
   "outputs": [],
   "source": [
    "## you should change your model artifact after sagemaker training job\n",
    "s3_model_path = 's3://sagemaker-us-east-1-741261399688/pytorch-training-2022-04-22-12-50-11-763/output/model.tar.gz'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d9a7046",
   "metadata": {},
   "source": [
    "find the image uri from ECR "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bccde74b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'741261399688.dkr.ecr.us-east-1.amazonaws.com/monai-classification:latest'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "container_image_uri = '{0}.dkr.ecr.{1}.amazonaws.com/{2}:latest'.format(account_id, region, prefix)\n",
    "container_image_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "73fe6279",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import gmtime, strftime\n",
    "from sagemaker.model import Model\n",
    "\n",
    "model_name = 'medical-image-classification-model-server' + strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "\n",
    "model = Model(model_data = s3_model_path,\n",
    "              image_uri = container_image_uri,\n",
    "              env = {\n",
    "                  'SAGEMAKER_PROGRAM': 'predictor'\n",
    "              },\n",
    "              role=role,\n",
    "              name = model_name,\n",
    "              predictor_cls = sagemaker.predictor.Predictor,\n",
    "              sagemaker_session=sess #comment this line for local mode.\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ff493414",
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker_client = boto3.client('sagemaker', region_name=region)\n",
    "                                \n",
    "model_name = 'medical-image-classification-model-server' + strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "\n",
    "create_model_response = sagemaker_client.create_model(\n",
    "    ModelName = model_name,\n",
    "    ExecutionRoleArn = role,\n",
    "    PrimaryContainer = {\n",
    "        'Image': container_image_uri,\n",
    "        'ModelDataUrl': s3_model_path,\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0d9a96a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ModelArn': 'arn:aws:sagemaker:us-east-1:741261399688:model/medical-image-classification-model-server2022-04-26-03-28-52',\n",
       " 'ResponseMetadata': {'RequestId': '54522cc4-c6ce-4a04-8990-40a2cfc43f37',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': '54522cc4-c6ce-4a04-8990-40a2cfc43f37',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '122',\n",
       "   'date': 'Tue, 26 Apr 2022 03:28:51 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_model_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "706e59d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_prefix = 'Inference_output'\n",
    "bucket = sagemaker_session.default_bucket()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2594b259",
   "metadata": {},
   "outputs": [],
   "source": [
    "## create a endpoint configure "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bb5754c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created EndpointConfig: arn:aws:sagemaker:us-east-1:707754867495:endpoint-config/medicalimageendpointconfig-2022-02-23-08-19-43\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "from time import gmtime, strftime\n",
    "\n",
    "# Create an endpoint config name. Here we create one based on the date  \n",
    "# so it we can search endpoints based on creation time.\n",
    "endpoint_config_name = f\"MedicalImageEndpointConfig-{strftime('%Y-%m-%d-%H-%M-%S', gmtime())}\"\n",
    "\n",
    "# The name of the model that you want to host. This is the name that you specified when creating the model.\n",
    "model_name='pytorch-inference-2022-01-27-08-48-43-106'\n",
    "\n",
    "create_endpoint_config_response = sagemaker_client.create_endpoint_config(\n",
    "    EndpointConfigName=endpoint_config_name, # You will specify this name in a CreateEndpoint request.\n",
    "    # List of ProductionVariant objects, one for each model that you want to host at this endpoint.\n",
    "    ProductionVariants=[\n",
    "        {\n",
    "            \"VariantName\": \"variant1\", # The name of the production variant.\n",
    "            \"ModelName\": model_name, \n",
    "            \"InstanceType\": \"ml.m5.xlarge\", # Specify the compute instance type.\n",
    "            \"InitialInstanceCount\": 1 # Number of instances to launch initially.\n",
    "        }\n",
    "    ],\n",
    "    AsyncInferenceConfig={\n",
    "        \"OutputConfig\": {\n",
    "            # Location to upload response outputs when no location is provided in the request.\n",
    "            \"S3OutputPath\": f\"s3://{bucket}/{bucket_prefix}/output\",\n",
    "            # (Optional) specify Amazon SNS topics\n",
    "            \n",
    "        },\n",
    "        \"ClientConfig\": {\n",
    "            # (Optional) Specify the max number of inflight invocations per instance\n",
    "            # If no value is provided, Amazon SageMaker will choose an optimal value for you\n",
    "            \"MaxConcurrentInvocationsPerInstance\": 4\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "print(f\"Created EndpointConfig: {create_endpoint_config_response['EndpointConfigArn']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "951318cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint_name = 'AsynchronousMedicalInference3' \n",
    "\n",
    "# The name of the endpoint configuration associated with this endpoint.\n",
    "\n",
    "create_endpoint_response = sagemaker_client.create_endpoint(\n",
    "                                            EndpointName=endpoint_name, \n",
    "                                            EndpointConfigName=endpoint_config_name,\n",
    "                                           ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8887295a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AsynchronousMedicalInference3'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "endpoint_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "18134986",
   "metadata": {},
   "outputs": [],
   "source": [
    "## invoke the endpoint\n",
    "sagemaker_runtime = boto3.client(\"sagemaker-runtime\", region_name='us-east-1')\n",
    "input_location = 's3://sagemaker-us-east-1-707754867495/inference_input/test-2.json'\n",
    "response = sagemaker_runtime.invoke_endpoint_async(\n",
    "    EndpointName=endpoint_name,\n",
    "    InputLocation=input_location\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ddb4ec51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': '0b1e8cca-c5a0-4920-a093-2cefa7a50929',\n",
       "  'HTTPStatusCode': 202,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': '0b1e8cca-c5a0-4920-a093-2cefa7a50929',\n",
       "   'x-amzn-sagemaker-outputlocation': 's3://sagemaker-us-east-1-707754867495/Inference_output/output/f99f3083-c41a-4deb-8dce-d8c9b759138a.out',\n",
       "   'date': 'Wed, 23 Feb 2022 09:34:25 GMT',\n",
       "   'content-type': 'application/json',\n",
       "   'content-length': '54'},\n",
       "  'RetryAttempts': 0},\n",
       " 'OutputLocation': 's3://sagemaker-us-east-1-707754867495/Inference_output/output/f99f3083-c41a-4deb-8dce-d8c9b759138a.out',\n",
       " 'InferenceId': 'd2c2d7d9-1179-4d9c-b90f-26c6c8b063b4'}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b98d6f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
